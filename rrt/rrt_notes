1. make_rrt.py creates RRTs with several command line options and saves the floormap image, with the RRT, the free image, and the parameters to files.
$ python -i make_rrt.py --mesh_name='/home/reza/Datasets/GibsonEnv/gibson/assets/dataset/Allensville/mesh_z_up.obj' --height=0.47
This file will generate floormap.png, config.pickle, free.png, rrt.npz in /home/reza/Datasets/GibsonEnv/gibson/assets/dataset/Allensville/.
Usually there are 3 floors for each GibsonEnv scene. So you need to decide the Z value when you run meshcut(). You can run find_peak_density_of_Zs.py to find the maximum density of Z values of the given trajectory points.
There is an example shell file 'run_make_rrt.sh' show you how to run make_rrt.py

2. 
$ python -i find_path.py --dir='/home/reza/Datasets/GibsonEnv/gibson/assets/dataset/Allensville'
floormap_with_path.png is created.

3. When the code generates the occupancy maps, the programmer controlled the size of the map through px_per_meter parameter in the rrt.py make_free_space_image() function.
This is a clever design choice, better than my old drawing map code.

4. Call my_find_path.py to generate the path given start point and end point.
my_find_path.py also contains code to generate the points_i.txt files saved in points folder through a list of start locations.
Call expand_rrt_traj.py or expand_all_rrt_traj.py to smooth the traj of points generated by my_find_path.py.
What expand_rrt_traj.py does is to add intermediate turning actions between consecutive points.
The pose results are saved in poses.npy. Actions between consecutive poses are saved in poses_actions.npy.
Call visualize_poses.py to visualize the poses on the free.png as acute trianges.
Call my_random_nav.py to take a picture at each pose along the whole trajectory.
Observations are saved in obs_Allensville_train folder.

5. The minkowski code is saved in boost_minkowski_sum folder in the rrt folder.
To compile the code, do
$ g++ -o my_s my_minkowski.cpp
I use freemap2poly.py in rrt folder to generate the contour points files.
Use https://www.w3schools.com/graphics/tryit.asp?filename=trysvg_polygon to visualize the polygon.
Boost Minkowski sum tutorial is at https://www.boost.org/doc/libs/1_55_0/libs/polygon/doc/gtl_minkowski_tutorial.htm
You haven't figure out how to visualize the polygon_with_holes on SVG graphs yet.
You haven't figure out the size of the robot yet.


Motion planning with dynamics
1. Use Minkowski sum to adapt the free map into configuration space where we take robot’s size into consideration. Robot size is controlled by default scale in the Husky class in robot_locomotors.py. And then redo RRT on the adapted configuration space so that the space where the agent doesn’t fit won’t be chosen.
2. When I was looking for the size of the agent, I realize that if I change the scale of the agent to a very small number, it was 0.6 by default, we can take it as a point in space so that the agent is able to fit everywhere. This hypothesis becomes true when I change the scale into 0.01. So now it’s similar to the Doom environment where the agent is just a point and we can get its observation from any viewpoint. 
3. This github issue mentioned how to abstract away all the low level dynamics so that I can control the agent same way as I did in the Doom environment. By calling forward or backward, the robot will move a fixed distance. https://github.com/StanfordVL/GibsonEnv/issues/32
4. The viewpoints generated by RRT is not continuous enough where I found a large turning between consecutive observations from time to time. I need to fix this.

